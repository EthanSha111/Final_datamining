{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MNIST Experiments: Positional Encoding Variants\n",
        "\n",
        "This notebook runs and compares small ViT models on MNIST using different\n",
        "relative positional encoding (RPE) mechanisms:\n",
        "\n",
        "- RoPE baseline\n",
        "- Cayley-STRING with dense S\n",
        "- Reflection-based STRING\n",
        "- Sparse-S Cayley-STRING (varying sparsity f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "import torch\n",
        "\n",
        "from data_utils import set_seed\n",
        "\n",
        "from train_eval import ExperimentConfig, run_experiment\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "set_seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n",
            "100.0%\n",
            "100.0%\n",
            "100.0%\n",
            "/Users/ethansha/anaconda3/envs/worldquant/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1/2] train_loss=0.5610, train_acc=0.8262, val_loss=0.1995, val_acc=0.9428, time=50.02s\n",
            "[Epoch 2/2] train_loss=0.1448, train_acc=0.9581, val_loss=0.1536, val_acc=0.9535, time=44.63s\n",
            "{\n",
            "  \"config\": {\n",
            "    \"dataset\": \"mnist\",\n",
            "    \"pos_variant\": \"rope\",\n",
            "    \"img_size\": 28,\n",
            "    \"patch_size\": 7,\n",
            "    \"in_chans\": 1,\n",
            "    \"num_classes\": 10,\n",
            "    \"emb_dim\": 128,\n",
            "    \"depth\": 4,\n",
            "    \"n_heads\": 4,\n",
            "    \"batch_size\": 128,\n",
            "    \"epochs\": 2,\n",
            "    \"lr\": 0.0003,\n",
            "    \"weight_decay\": 0.01,\n",
            "    \"f_sparse\": null\n",
            "  },\n",
            "  \"final_train_loss\": 0.1447838130871455,\n",
            "  \"final_train_acc\": 0.9581166666666666,\n",
            "  \"final_val_loss\": 0.1535803920030594,\n",
            "  \"final_val_acc\": 0.9535,\n",
            "  \"avg_epoch_time_sec\": 47.322014927864075,\n",
            "  \"inference_time_ms_per_batch\": 28.18448543548584\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Sanity check: RoPE-only ViT on MNIST\n",
        "\n",
        "config_rope_mnist = ExperimentConfig(\n",
        "    dataset=\"mnist\",\n",
        "    pos_variant=\"rope\",\n",
        "    img_size=28,\n",
        "    patch_size=7,\n",
        "    in_chans=1,\n",
        "    num_classes=10,\n",
        "    emb_dim=128,\n",
        "    depth=4,\n",
        "    n_heads=4,\n",
        "    batch_size=128,\n",
        "    epochs=2,\n",
        "    lr=3e-4,\n",
        ")\n",
        "\n",
        "results_rope_mnist = run_experiment(config_rope_mnist, device=DEVICE)\n",
        "print(json.dumps(results_rope_mnist, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1/2] train_loss=0.5377, train_acc=0.8342, val_loss=0.2083, val_acc=0.9396, time=262.99s\n",
            "[Epoch 2/2] train_loss=0.1486, train_acc=0.9563, val_loss=0.1118, val_acc=0.9691, time=260.01s\n",
            "{\n",
            "  \"config\": {\n",
            "    \"dataset\": \"mnist\",\n",
            "    \"pos_variant\": \"cayley_dense\",\n",
            "    \"img_size\": 28,\n",
            "    \"patch_size\": 7,\n",
            "    \"in_chans\": 1,\n",
            "    \"num_classes\": 10,\n",
            "    \"emb_dim\": 128,\n",
            "    \"depth\": 4,\n",
            "    \"n_heads\": 4,\n",
            "    \"batch_size\": 128,\n",
            "    \"epochs\": 2,\n",
            "    \"lr\": 0.0003,\n",
            "    \"weight_decay\": 0.01,\n",
            "    \"f_sparse\": null\n",
            "  },\n",
            "  \"final_train_loss\": 0.14857388066848118,\n",
            "  \"final_train_acc\": 0.9563333333333334,\n",
            "  \"final_val_loss\": 0.11180496111512184,\n",
            "  \"final_val_acc\": 0.9691,\n",
            "  \"avg_epoch_time_sec\": 261.49744296073914,\n",
            "  \"inference_time_ms_per_batch\": 117.74463653564453\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Baseline Cayley-STRING (dense S) on MNIST\n",
        "\n",
        "config_cayley_dense_mnist = ExperimentConfig(\n",
        "    dataset=\"mnist\",\n",
        "    pos_variant=\"cayley_dense\",\n",
        "    img_size=28,\n",
        "    patch_size=7,\n",
        "    in_chans=1,\n",
        "    num_classes=10,\n",
        "    emb_dim=128,\n",
        "    depth=4,\n",
        "    n_heads=4,\n",
        "    batch_size=128,\n",
        "    epochs=2,\n",
        "    lr=3e-4,\n",
        ")\n",
        "\n",
        "results_cayley_dense_mnist = run_experiment(config_cayley_dense_mnist, device=DEVICE)\n",
        "print(json.dumps(results_cayley_dense_mnist, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1/2] train_loss=0.6917, train_acc=0.7828, val_loss=0.2794, val_acc=0.9147, time=48.00s\n",
            "[Epoch 2/2] train_loss=0.2188, train_acc=0.9345, val_loss=0.1761, val_acc=0.9458, time=69.27s\n",
            "{\n",
            "  \"config\": {\n",
            "    \"dataset\": \"mnist\",\n",
            "    \"pos_variant\": \"reflection\",\n",
            "    \"img_size\": 28,\n",
            "    \"patch_size\": 7,\n",
            "    \"in_chans\": 1,\n",
            "    \"num_classes\": 10,\n",
            "    \"emb_dim\": 128,\n",
            "    \"depth\": 4,\n",
            "    \"n_heads\": 4,\n",
            "    \"batch_size\": 128,\n",
            "    \"epochs\": 2,\n",
            "    \"lr\": 0.0003,\n",
            "    \"weight_decay\": 0.01,\n",
            "    \"f_sparse\": null\n",
            "  },\n",
            "  \"final_train_loss\": 0.21880235421657562,\n",
            "  \"final_train_acc\": 0.9345333333333333,\n",
            "  \"final_val_loss\": 0.176052467751503,\n",
            "  \"final_val_acc\": 0.9458,\n",
            "  \"avg_epoch_time_sec\": 58.63502240180969,\n",
            "  \"inference_time_ms_per_batch\": 57.71787166595459\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Reflection-based STRING on MNIST\n",
        "\n",
        "config_reflection_mnist = ExperimentConfig(\n",
        "    dataset=\"mnist\",\n",
        "    pos_variant=\"reflection\",\n",
        "    img_size=28,\n",
        "    patch_size=7,\n",
        "    in_chans=1,\n",
        "    num_classes=10,\n",
        "    emb_dim=128,\n",
        "    depth=4,\n",
        "    n_heads=4,\n",
        "    batch_size=128,\n",
        "    epochs=2,\n",
        "    lr=3e-4,\n",
        ")\n",
        "\n",
        "results_reflection_mnist = run_experiment(config_reflection_mnist, device=DEVICE)\n",
        "print(json.dumps(results_reflection_mnist, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running sparse Cayley-STRING with f=1.0...\n",
            "[Epoch 1/2] train_loss=0.5314, train_acc=0.8384, val_loss=0.1728, val_acc=0.9518, time=318.82s\n",
            "[Epoch 2/2] train_loss=0.1388, train_acc=0.9590, val_loss=0.1082, val_acc=0.9674, time=300.90s\n",
            "\n",
            "Running sparse Cayley-STRING with f=0.5...\n",
            "[Epoch 1/2] train_loss=0.5574, train_acc=0.8282, val_loss=0.1715, val_acc=0.9503, time=285.48s\n",
            "[Epoch 2/2] train_loss=0.1368, train_acc=0.9598, val_loss=0.1022, val_acc=0.9690, time=280.93s\n",
            "\n",
            "Running sparse Cayley-STRING with f=0.2...\n",
            "[Epoch 1/2] train_loss=0.5124, train_acc=0.8441, val_loss=0.1993, val_acc=0.9387, time=290.49s\n",
            "[Epoch 2/2] train_loss=0.1427, train_acc=0.9584, val_loss=0.1266, val_acc=0.9618, time=283.54s\n",
            "\n",
            "Running sparse Cayley-STRING with f=0.1...\n",
            "[Epoch 1/2] train_loss=0.5072, train_acc=0.8479, val_loss=0.1800, val_acc=0.9471, time=286.46s\n",
            "[Epoch 2/2] train_loss=0.1351, train_acc=0.9605, val_loss=0.1021, val_acc=0.9712, time=267.13s\n",
            "[\n",
            "  {\n",
            "    \"config\": {\n",
            "      \"dataset\": \"mnist\",\n",
            "      \"pos_variant\": \"cayley_sparse\",\n",
            "      \"img_size\": 28,\n",
            "      \"patch_size\": 7,\n",
            "      \"in_chans\": 1,\n",
            "      \"num_classes\": 10,\n",
            "      \"emb_dim\": 128,\n",
            "      \"depth\": 4,\n",
            "      \"n_heads\": 4,\n",
            "      \"batch_size\": 128,\n",
            "      \"epochs\": 2,\n",
            "      \"lr\": 0.0003,\n",
            "      \"weight_decay\": 0.01,\n",
            "      \"f_sparse\": 1.0\n",
            "    },\n",
            "    \"final_train_loss\": 0.1388445533156395,\n",
            "    \"final_train_acc\": 0.95905,\n",
            "    \"final_val_loss\": 0.10819547076970339,\n",
            "    \"final_val_acc\": 0.9674,\n",
            "    \"avg_epoch_time_sec\": 309.86070942878723,\n",
            "    \"inference_time_ms_per_batch\": 123.65849018096924\n",
            "  },\n",
            "  {\n",
            "    \"config\": {\n",
            "      \"dataset\": \"mnist\",\n",
            "      \"pos_variant\": \"cayley_sparse\",\n",
            "      \"img_size\": 28,\n",
            "      \"patch_size\": 7,\n",
            "      \"in_chans\": 1,\n",
            "      \"num_classes\": 10,\n",
            "      \"emb_dim\": 128,\n",
            "      \"depth\": 4,\n",
            "      \"n_heads\": 4,\n",
            "      \"batch_size\": 128,\n",
            "      \"epochs\": 2,\n",
            "      \"lr\": 0.0003,\n",
            "      \"weight_decay\": 0.01,\n",
            "      \"f_sparse\": 0.5\n",
            "    },\n",
            "    \"final_train_loss\": 0.13682164753278098,\n",
            "    \"final_train_acc\": 0.9597666666666667,\n",
            "    \"final_val_loss\": 0.1021550910755992,\n",
            "    \"final_val_acc\": 0.969,\n",
            "    \"avg_epoch_time_sec\": 283.2029250860214,\n",
            "    \"inference_time_ms_per_batch\": 115.50233364105225\n",
            "  },\n",
            "  {\n",
            "    \"config\": {\n",
            "      \"dataset\": \"mnist\",\n",
            "      \"pos_variant\": \"cayley_sparse\",\n",
            "      \"img_size\": 28,\n",
            "      \"patch_size\": 7,\n",
            "      \"in_chans\": 1,\n",
            "      \"num_classes\": 10,\n",
            "      \"emb_dim\": 128,\n",
            "      \"depth\": 4,\n",
            "      \"n_heads\": 4,\n",
            "      \"batch_size\": 128,\n",
            "      \"epochs\": 2,\n",
            "      \"lr\": 0.0003,\n",
            "      \"weight_decay\": 0.01,\n",
            "      \"f_sparse\": 0.2\n",
            "    },\n",
            "    \"final_train_loss\": 0.14268141006628673,\n",
            "    \"final_train_acc\": 0.9584333333333334,\n",
            "    \"final_val_loss\": 0.12662562795132398,\n",
            "    \"final_val_acc\": 0.9618,\n",
            "    \"avg_epoch_time_sec\": 287.0174409151077,\n",
            "    \"inference_time_ms_per_batch\": 116.48850440979004\n",
            "  },\n",
            "  {\n",
            "    \"config\": {\n",
            "      \"dataset\": \"mnist\",\n",
            "      \"pos_variant\": \"cayley_sparse\",\n",
            "      \"img_size\": 28,\n",
            "      \"patch_size\": 7,\n",
            "      \"in_chans\": 1,\n",
            "      \"num_classes\": 10,\n",
            "      \"emb_dim\": 128,\n",
            "      \"depth\": 4,\n",
            "      \"n_heads\": 4,\n",
            "      \"batch_size\": 128,\n",
            "      \"epochs\": 2,\n",
            "      \"lr\": 0.0003,\n",
            "      \"weight_decay\": 0.01,\n",
            "      \"f_sparse\": 0.1\n",
            "    },\n",
            "    \"final_train_loss\": 0.13512990868091584,\n",
            "    \"final_train_acc\": 0.9605333333333334,\n",
            "    \"final_val_loss\": 0.10213128931820392,\n",
            "    \"final_val_acc\": 0.9712,\n",
            "    \"avg_epoch_time_sec\": 276.79396891593933,\n",
            "    \"inference_time_ms_per_batch\": 112.16816902160645\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# Sparse-S Cayley-STRING variants on MNIST\n",
        "\n",
        "sparse_results = []\n",
        "for f in [1.0, 0.5, 0.2, 0.1]:\n",
        "    print(f\"\\nRunning sparse Cayley-STRING with f={f}...\")\n",
        "    config_sparse = ExperimentConfig(\n",
        "        dataset=\"mnist\",\n",
        "        pos_variant=\"cayley_sparse\",\n",
        "        img_size=28,\n",
        "        patch_size=7,\n",
        "        in_chans=1,\n",
        "        num_classes=10,\n",
        "        emb_dim=128,\n",
        "        depth=4,\n",
        "        n_heads=4,\n",
        "        batch_size=128,\n",
        "        epochs=2,\n",
        "        lr=3e-4,\n",
        "        f_sparse=f,\n",
        "    )\n",
        "    res = run_experiment(config_sparse, device=DEVICE)\n",
        "    sparse_results.append(res)\n",
        "\n",
        "print(json.dumps(sparse_results, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CIFAR-10 Experiments\n",
        "\n",
        "Quick runs to compare RoPE, dense Cayley-STRING, Reflection-STRING, and Sparse-S Cayley-STRING on CIFAR-10. Adjust `epochs`/`emb_dim`/`depth` as needed; current settings are small to keep runtime manageable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running CIFAR-10 RoPE...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1/1] train_loss=1.5843, train_acc=0.4229, val_loss=1.3494, val_acc=0.5160, time=196.69s\n",
            "{\n",
            "  \"config\": {\n",
            "    \"dataset\": \"cifar10\",\n",
            "    \"pos_variant\": \"rope\",\n",
            "    \"img_size\": 32,\n",
            "    \"patch_size\": 4,\n",
            "    \"in_chans\": 3,\n",
            "    \"num_classes\": 10,\n",
            "    \"emb_dim\": 192,\n",
            "    \"depth\": 4,\n",
            "    \"n_heads\": 4,\n",
            "    \"batch_size\": 128,\n",
            "    \"epochs\": 1,\n",
            "    \"lr\": 0.0003,\n",
            "    \"weight_decay\": 0.01,\n",
            "    \"f_sparse\": null\n",
            "  },\n",
            "  \"final_train_loss\": 1.5842964737319947,\n",
            "  \"final_train_acc\": 0.42292,\n",
            "  \"final_val_loss\": 1.349433870124817,\n",
            "  \"final_val_acc\": 0.516,\n",
            "  \"avg_epoch_time_sec\": 196.68830108642578,\n",
            "  \"inference_time_ms_per_batch\": 187.40193843841553\n",
            "}\n",
            "\n",
            "Running CIFAR-10 Cayley (dense)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(20673) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(20690) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1/1] train_loss=1.5750, train_acc=0.4279, val_loss=1.3917, val_acc=0.4933, time=3682.29s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(21373) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(21387) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"config\": {\n",
            "    \"dataset\": \"cifar10\",\n",
            "    \"pos_variant\": \"cayley_dense\",\n",
            "    \"img_size\": 32,\n",
            "    \"patch_size\": 4,\n",
            "    \"in_chans\": 3,\n",
            "    \"num_classes\": 10,\n",
            "    \"emb_dim\": 192,\n",
            "    \"depth\": 4,\n",
            "    \"n_heads\": 4,\n",
            "    \"batch_size\": 128,\n",
            "    \"epochs\": 1,\n",
            "    \"lr\": 0.0003,\n",
            "    \"weight_decay\": 0.01,\n",
            "    \"f_sparse\": null\n",
            "  },\n",
            "  \"final_train_loss\": 1.5749987294387817,\n",
            "  \"final_train_acc\": 0.42792,\n",
            "  \"final_val_loss\": 1.3916774576187134,\n",
            "  \"final_val_acc\": 0.4933,\n",
            "  \"avg_epoch_time_sec\": 3682.2861709594727,\n",
            "  \"inference_time_ms_per_batch\": 34389.75887298584\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# CIFAR-10: RoPE and dense Cayley-STRING (quick baseline runs)\n",
        "\n",
        "config_rope_cifar = ExperimentConfig(\n",
        "    dataset=\"cifar10\",\n",
        "    pos_variant=\"rope\",\n",
        "    img_size=32,\n",
        "    patch_size=4,\n",
        "    in_chans=3,\n",
        "    num_classes=10,\n",
        "    emb_dim=192,\n",
        "    depth=4,\n",
        "    n_heads=4,\n",
        "    batch_size=128,\n",
        "    epochs=1,\n",
        "    lr=3e-4,\n",
        ")\n",
        "\n",
        "config_cayley_dense_cifar = ExperimentConfig(\n",
        "    dataset=\"cifar10\",\n",
        "    pos_variant=\"cayley_dense\",\n",
        "    img_size=32,\n",
        "    patch_size=4,\n",
        "    in_chans=3,\n",
        "    num_classes=10,\n",
        "    emb_dim=192,\n",
        "    depth=4,\n",
        "    n_heads=4,\n",
        "    \n",
        "    batch_size=128,\n",
        "    epochs=1,\n",
        "    lr=3e-4,\n",
        ")\n",
        "\n",
        "print(\"Running CIFAR-10 RoPE...\")\n",
        "results_rope_cifar = run_experiment(config_rope_cifar, device=DEVICE)\n",
        "print(json.dumps(results_rope_cifar, indent=2))\n",
        "\n",
        "print(\"\\nRunning CIFAR-10 Cayley (dense)...\")\n",
        "results_cayley_dense_cifar = run_experiment(config_cayley_dense_cifar, device=DEVICE)\n",
        "print(json.dumps(results_cayley_dense_cifar, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running CIFAR-10 Sparse Cayley-STRING with f=1.0...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(21577) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(21593) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(42495) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(42520) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1/1] train_loss=1.5589, train_acc=0.4312, val_loss=1.2992, val_acc=0.5271, time=43580.31s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(43894) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(43908) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running CIFAR-10 Sparse Cayley-STRING with f=0.3...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(44214) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(44230) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(64821) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(64840) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1/1] train_loss=1.5592, train_acc=0.4306, val_loss=1.2896, val_acc=0.5385, time=3492.91s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(65652) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(65668) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running CIFAR-10 Sparse Cayley-STRING with f=0.1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(65857) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(65889) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(82303) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(82319) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1/1] train_loss=1.5895, train_acc=0.4212, val_loss=1.3522, val_acc=0.5153, time=32885.43s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(82861) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(82866) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running CIFAR-10 Reflection-STRING...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(83044) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(83059) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(84797) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(84811) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1/1] train_loss=1.6229, train_acc=0.4043, val_loss=1.4004, val_acc=0.4925, time=200.32s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(85127) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(85143) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"config\": {\n",
            "    \"dataset\": \"cifar10\",\n",
            "    \"pos_variant\": \"reflection\",\n",
            "    \"img_size\": 32,\n",
            "    \"patch_size\": 4,\n",
            "    \"in_chans\": 3,\n",
            "    \"num_classes\": 10,\n",
            "    \"emb_dim\": 192,\n",
            "    \"depth\": 4,\n",
            "    \"n_heads\": 4,\n",
            "    \"batch_size\": 128,\n",
            "    \"epochs\": 1,\n",
            "    \"lr\": 0.0003,\n",
            "    \"weight_decay\": 0.01,\n",
            "    \"f_sparse\": null\n",
            "  },\n",
            "  \"final_train_loss\": 1.6229468309020996,\n",
            "  \"final_train_acc\": 0.40426,\n",
            "  \"final_val_loss\": 1.4004474094390869,\n",
            "  \"final_val_acc\": 0.4925,\n",
            "  \"avg_epoch_time_sec\": 200.32258820533752,\n",
            "  \"inference_time_ms_per_batch\": 165.4984712600708\n",
            "}\n",
            "\n",
            "Sparse CIFAR-10 results:\n",
            "[\n",
            "  {\n",
            "    \"config\": {\n",
            "      \"dataset\": \"cifar10\",\n",
            "      \"pos_variant\": \"cayley_sparse\",\n",
            "      \"img_size\": 32,\n",
            "      \"patch_size\": 4,\n",
            "      \"in_chans\": 3,\n",
            "      \"num_classes\": 10,\n",
            "      \"emb_dim\": 192,\n",
            "      \"depth\": 4,\n",
            "      \"n_heads\": 4,\n",
            "      \"batch_size\": 128,\n",
            "      \"epochs\": 1,\n",
            "      \"lr\": 0.0003,\n",
            "      \"weight_decay\": 0.01,\n",
            "      \"f_sparse\": 1.0\n",
            "    },\n",
            "    \"final_train_loss\": 1.5588574738311767,\n",
            "    \"final_train_acc\": 0.43116,\n",
            "    \"final_val_loss\": 1.2992087114334105,\n",
            "    \"final_val_acc\": 0.5271,\n",
            "    \"avg_epoch_time_sec\": 43580.30637192726,\n",
            "    \"inference_time_ms_per_batch\": 814.9464130401611\n",
            "  },\n",
            "  {\n",
            "    \"config\": {\n",
            "      \"dataset\": \"cifar10\",\n",
            "      \"pos_variant\": \"cayley_sparse\",\n",
            "      \"img_size\": 32,\n",
            "      \"patch_size\": 4,\n",
            "      \"in_chans\": 3,\n",
            "      \"num_classes\": 10,\n",
            "      \"emb_dim\": 192,\n",
            "      \"depth\": 4,\n",
            "      \"n_heads\": 4,\n",
            "      \"batch_size\": 128,\n",
            "      \"epochs\": 1,\n",
            "      \"lr\": 0.0003,\n",
            "      \"weight_decay\": 0.01,\n",
            "      \"f_sparse\": 0.3\n",
            "    },\n",
            "    \"final_train_loss\": 1.5592499726104736,\n",
            "    \"final_train_acc\": 0.43064,\n",
            "    \"final_val_loss\": 1.2895768337249756,\n",
            "    \"final_val_acc\": 0.5385,\n",
            "    \"avg_epoch_time_sec\": 3492.912398815155,\n",
            "    \"inference_time_ms_per_batch\": 1051.9256830215454\n",
            "  },\n",
            "  {\n",
            "    \"config\": {\n",
            "      \"dataset\": \"cifar10\",\n",
            "      \"pos_variant\": \"cayley_sparse\",\n",
            "      \"img_size\": 32,\n",
            "      \"patch_size\": 4,\n",
            "      \"in_chans\": 3,\n",
            "      \"num_classes\": 10,\n",
            "      \"emb_dim\": 192,\n",
            "      \"depth\": 4,\n",
            "      \"n_heads\": 4,\n",
            "      \"batch_size\": 128,\n",
            "      \"epochs\": 1,\n",
            "      \"lr\": 0.0003,\n",
            "      \"weight_decay\": 0.01,\n",
            "      \"f_sparse\": 0.1\n",
            "    },\n",
            "    \"final_train_loss\": 1.5894742819595338,\n",
            "    \"final_train_acc\": 0.42116,\n",
            "    \"final_val_loss\": 1.3522385585784913,\n",
            "    \"final_val_acc\": 0.5153,\n",
            "    \"avg_epoch_time_sec\": 32885.43090033531,\n",
            "    \"inference_time_ms_per_batch\": 852.0473957061768\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# CIFAR-10: Reflection-STRING and Sparse-S Cayley-STRING\n",
        "\n",
        "config_reflection_cifar = ExperimentConfig(\n",
        "    dataset=\"cifar10\",\n",
        "    pos_variant=\"reflection\",\n",
        "    img_size=32,\n",
        "    patch_size=4,\n",
        "    in_chans=3,\n",
        "    num_classes=10,\n",
        "    emb_dim=192,\n",
        "    depth=4,\n",
        "    n_heads=4,\n",
        "    batch_size=128,\n",
        "    epochs=1,\n",
        "    lr=3e-4,\n",
        ")\n",
        "\n",
        "sparse_results_cifar = []\n",
        "for f in [1.0, 0.3, 0.1]:\n",
        "    print(f\"\\nRunning CIFAR-10 Sparse Cayley-STRING with f={f}...\")\n",
        "    config_sparse_cifar = ExperimentConfig(\n",
        "        dataset=\"cifar10\",\n",
        "        pos_variant=\"cayley_sparse\",\n",
        "        img_size=32,\n",
        "        patch_size=4,\n",
        "        in_chans=3,\n",
        "        num_classes=10,\n",
        "        emb_dim=192,\n",
        "        depth=4,\n",
        "        n_heads=4,\n",
        "        batch_size=128,\n",
        "        epochs=1,\n",
        "        lr=3e-4,\n",
        "        f_sparse=f,\n",
        "    )\n",
        "    res = run_experiment(config_sparse_cifar, device=DEVICE)\n",
        "    sparse_results_cifar.append(res)\n",
        "\n",
        "print(\"\\nRunning CIFAR-10 Reflection-STRING...\")\n",
        "results_reflection_cifar = run_experiment(config_reflection_cifar, device=DEVICE)\n",
        "print(json.dumps(results_reflection_cifar, indent=2))\n",
        "\n",
        "print(\"\\nSparse CIFAR-10 results:\")\n",
        "print(json.dumps(sparse_results_cifar, indent=2))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "worldquant",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
